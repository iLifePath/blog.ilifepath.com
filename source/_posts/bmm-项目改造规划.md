title: BMM 项目改造规划
date: 2015-08-03 15:48:02
categories: 项目
tags:
  - BMM
  - 迁移
  - 项目
  - 规划
  - Hadoop
---

![](http://7xjra2.com1.z0.glb.clouddn.com/saltlake.jpg)

#### 智能推荐 Hadoop 移植项目规划
- Hadoop 技术体系培训与学习
    - Map/Reduce 计算框架
    - HBase 数据库
    - HDFS 文件系统
    - Flume + Kafka 数据清洗工具

- 智能推荐改造点
    1. 热片统计
    2. 协同过滤模型改造
    3. 关联规则模型改造
        > - 热片统计是 MapReduce 框架的典型应用场景，不存在理论上的难度
        > - 协同过滤（复杂度为O2）采用 Hadoop 体系中的 Mahout 组件开发，如何把协同过滤算法适配到 MapReduce 框架需要研究，而且很可能不能完美适配
        > - 目前的关联规则（复杂度为O2）直接在数据库中使用存储过程执行，需要将算法逻辑抽离数据库，用高级语言重新编写，并适配到 MapReduce 框架

<!-- more -->

    4. 元数据导入流程
    5. 收视数据导入流程
        > ETL 流程是否需要适配到 Hadoop 体系尚待研究，原则上，高效的 ETL 过程可以完成很多简单统计计算，例如热片统计等，这也是 Hadoop 的典型应用场景

- 用户画像改造点
    1. 用 Java 语言改写整体逻辑
    2. 适配 MapReduce 计算框架
        > 用户画像计算过程较为线性（推荐算法模型复杂度为O2，用户画像复杂度为O），适配到 MapReduce 框架也不存在理论上的难度

- 整体架构改造
    - 存储层改造：模型计算上提到中央后，结果存储是否上提到中央？
    - 服务层改造：如果存储层也上提到中央，服务层也需要考虑是否上提到中央？
    - 性能改造：：如果存储层和服务层都上提中央，则服务层性能需要扩充；如果存储层和服务层都保留在驻地，那么结果分发和同步机制需要重新考虑；
        > 以上问题需要重新设计和规划，综合权衡和考虑，牵涉面不小，但难度不大

**个人总结：**
智能推荐+用户画像的 Hadoop 移植个人向来非常赞成，特别是采用中央统一计算，能够极大地降低数据稀疏度，提高结果精准度，还能方便运维和管理，缩减资源消耗；中央计算的代价之一是牺牲地域特性，但是小驻地因此可以获得良好的推荐效果，全国各驻地的体验也能达到一致，因此这点牺牲可以忽略；中央计算代价之二是技术门槛，目前 Hadoop 集群基础设施已经完备，仅在业务层面上需要进行适配改造，服务架构上做相应调整，相比所获得的好处，应该是值得的……另外，个人认为这是智能推荐+用户画像系统平台化的一个很好地契机，推动智能推荐+用户画像系统。

